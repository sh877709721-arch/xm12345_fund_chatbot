from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy.sql import text as sql_text
import pandas as pd
import logging
from io import BytesIO
from app.config.database import global_schema
from app.model.knowledge import KnowledgeData, KnowledgeStatusEnum
from app.core.embeddings_utils import get_text_embeddings_default

logger = logging.getLogger(__name__)


class KnowledgeDataIndexService:
    """Excel æ•°æ®ç´¢å¼•æœåŠ¡"""

    def __init__(self, db: Session):
        self.db = db

    def parse_excel_to_jsonb(
        self,
        file_content: bytes,
        sheet_name: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è§£æ Excel æ–‡ä»¶ä¸º JSON æ ¼å¼

        Args:
            file_content: Excel æ–‡ä»¶å†…å®¹ï¼ˆå­—èŠ‚ï¼‰
            sheet_name: å·¥ä½œè¡¨åç§°ï¼ˆé»˜è®¤ç¬¬ä¸€ä¸ªï¼‰

        Returns:
            å¯¹è±¡æ•°ç»„: [{åˆ—1: å€¼1, åˆ—2: å€¼2}, ...]
        """
        try:
            # è¯»å– Excel
            df = pd.read_excel(
                BytesIO(file_content),
                sheet_name=sheet_name or 0
            )

            # å¤„ç† NaN å€¼
            df = df.fillna("")

            # è½¬æ¢ä¸ºå¯¹è±¡æ•°ç»„
            data = df.to_dict('records')

            logger.info(f"âœ… Excel è§£ææˆåŠŸ: {len(data)} è¡Œ, {len(df.columns)} åˆ—")

            return data

        except Exception as e:
            logger.error(f"âŒ Excel è§£æå¤±è´¥: {e}")
            raise ValueError(f"Excel æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")

    def save_knowledge_data_row(
        self,
        knowledge_id: int,
        row_data: Dict[str, Any],
        created_by: Optional[int] = None
    ) -> KnowledgeData:
        """
        ä¿å­˜å•è¡ŒçŸ¥è¯†æ•°æ®åˆ° knowledge_data è¡¨

        Args:
            knowledge_id: çŸ¥è¯†ID
            row_data: å•è¡Œæ•°æ®ï¼ˆå¯¹è±¡æ ¼å¼ï¼‰
            created_by: åˆ›å»ºäººID

        Returns:
            KnowledgeData å®ä¾‹
        """
        try:
            # åˆ›å»ºæ–°è®°å½•ï¼ˆæ¯è¡Œä¸€æ¡è®°å½•ï¼‰
            knowledge_data = KnowledgeData(
                knowledge_id=knowledge_id,
                content=row_data,  # å­˜å‚¨å•è¡Œæ•°æ®
                status=KnowledgeStatusEnum.active,
                created_by=created_by
            )

            self.db.add(knowledge_data)
            self.db.flush()  # âœ… ä½¿ç”¨ flush è·å– IDï¼Œä½†ä¸ç«‹å³æäº¤æ•´ä¸ªäº‹åŠ¡

            return knowledge_data

        except Exception as e:
            self.db.rollback()  # âœ… å‘ç”Ÿå¼‚å¸¸æ—¶å›æ»š
            logger.error(f"âŒ æ•°æ®è¡Œä¿å­˜å¤±è´¥: {e}")
            raise

    def create_fts_index_for_row(
        self,
        knowledge_data: KnowledgeData
    ) -> bool:
        """
        ä¸ºå•è¡Œæ•°æ®åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•å’Œå‘é‡ç´¢å¼•

        Args:
            knowledge_data: KnowledgeData å®ä¾‹

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # æå–è¯¥è¡Œæ•°æ®çš„æ‰€æœ‰æ–‡æœ¬ï¼Œä¿ç•™é”®å€¼å¯¹ç»“æ„ï¼ˆåŒ…å«è¡¨å¤´ä¿¡æ¯ï¼‰
            row_text = " ".join(
                f"{k}:{v}"
                for k, v in knowledge_data.content.items()
                if v is not None and str(v).strip()
            )

            # âœ… ç©ºæ–‡æœ¬æ£€æŸ¥
            if not row_text:
                logger.warning(f"âš ï¸ è¡Œæ•°æ® {knowledge_data.id} æ²¡æœ‰å¯ç´¢å¼•çš„æ–‡æœ¬å†…å®¹")
                return True

            # 1. è·å–æ–‡æœ¬å‘é‡
            embedding = get_text_embeddings_default(row_text)
            vector_str = None

            if not embedding:
                logger.warning(f"âš ï¸ è¡Œæ•°æ® {knowledge_data.id} å‘é‡åŒ–å¤±è´¥")
            else:
                # å°†å‘é‡è½¬æ¢ä¸º PostgreSQL vector æ ¼å¼ '[val1,val2,...]'
                vector_str = f'[{",".join(map(str, embedding))}]'

            # 2. æ›´æ–° FTS ç´¢å¼•å’Œå‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨ UPDATE è¯­å¥ï¼‰
            if embedding and vector_str:
                update_query = sql_text(f"""
                    UPDATE {global_schema}.knowledge_data
                    SET fts_content = to_tsvector('zhparsercfg', :text_content),
                        fts_vector = :vector_str
                    WHERE id = :knowledge_data_id
                """)
                self.db.execute(update_query, {
                    "knowledge_data_id": knowledge_data.id,
                    "text_content": row_text,
                    "vector_str": vector_str
                })
            else:
                # å¦‚æœå‘é‡åŒ–å¤±è´¥ï¼Œåªæ›´æ–° FTS ç´¢å¼•
                update_query = sql_text(f"""
                    UPDATE {global_schema}.knowledge_data
                    SET fts_content = to_tsvector('zhparsercfg', :text_content)
                    WHERE id = :knowledge_data_id
                """)
                self.db.execute(update_query, {
                    "knowledge_data_id": knowledge_data.id,
                    "text_content": row_text
                })

            return True

        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥ (ID: {knowledge_data.id}): {e}")
            raise

    def process_excel_upload(
        self,
        knowledge_id: int,
        file_content: bytes,
        created_by: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ Excel ä¸Šä¼ å¤„ç†æµç¨‹ï¼ˆæ¯è¡Œä¸€æ¡è®°å½•ï¼‰

        Args:
            knowledge_id: çŸ¥è¯†ID
            file_content: Excel æ–‡ä»¶å†…å®¹
            created_by: åˆ›å»ºäººID

        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # 1. è§£æ Excel
            logger.info(f"ğŸ“Š å¼€å§‹è§£æ Excel æ–‡ä»¶ï¼Œå¤§å°: {len(file_content)} bytes")
            rows = self.parse_excel_to_jsonb(file_content)

            if not rows:
                raise ValueError("Excel æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")

            logger.info(f"âœ… Excel è§£ææˆåŠŸ: {len(rows)} è¡Œ, {len(rows[0]) if rows else 0} åˆ—")

            # 2. å°†è¯¥ knowledge_id çš„æ—§æ•°æ®ç½®ä¸ºå¤±æ•ˆçŠ¶æ€ï¼ˆè½¯åˆ é™¤ï¼‰
            deactivate_query = sql_text(f"""
                UPDATE {global_schema}.knowledge_data
                SET status = :deleted_status
                WHERE knowledge_id = :knowledge_id
                    AND status = :active_status
            """)

            deactivated_result = self.db.execute(deactivate_query, {
                "deleted_status": KnowledgeStatusEnum.deleted.value,
                "knowledge_id": knowledge_id,
                "active_status": KnowledgeStatusEnum.active.value
            })

            deactivated_count = int(getattr(deactivated_result, 'rowcount', 0))
            if deactivated_count > 0:
                logger.info(f"ğŸ—‘ï¸  å·²å°† {deactivated_count} æ¡æ—§æ•°æ®ç½®ä¸ºå¤±æ•ˆçŠ¶æ€")
                self.db.commit()  # å…ˆæäº¤åˆ é™¤æ“ä½œ

            # 3. è¿­ä»£æ¯ä¸€è¡Œï¼Œä¿å­˜ä¸ºç‹¬ç«‹è®°å½•
            saved_records = []
            for idx, row_data in enumerate(rows, 1):
                try:
                    # ä¿å­˜å•è¡Œæ•°æ®
                    knowledge_data = self.save_knowledge_data_row(
                        knowledge_id=knowledge_id,
                        row_data=row_data,
                        created_by=created_by
                    )
                    saved_records.append(knowledge_data)

                    # ä¸ºè¯¥è¡Œåˆ›å»º FTS ç´¢å¼•
                    self.create_fts_index_for_row(knowledge_data)

                    # æ¯ 2000 è¡Œæäº¤ä¸€æ¬¡ï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤§
                    if idx % 2000 == 0:
                        self.db.commit()
                        logger.info(f"  âœ… å·²å¤„ç† {idx}/{len(rows)} è¡Œ")

                except Exception as e:
                    logger.error(f"âŒ å¤„ç†ç¬¬ {idx} è¡Œå¤±è´¥: {e}")
                    # å•è¡Œå¤±è´¥ä¸å½±å“å…¶ä»–è¡Œ
                    continue

            # 4. æœ€ç»ˆæäº¤å‰©ä½™çš„è®°å½•
            self.db.commit()

            logger.info(f"âœ… æ•°æ®ä¿å­˜å¹¶æäº¤æˆåŠŸ: å…±ä¿å­˜ {len(saved_records)} æ¡è®°å½•")
            logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: å¤±æ•ˆ {deactivated_count} æ¡æ—§æ•°æ®ï¼Œæ–°å¢ {len(saved_records)} æ¡æ–°æ•°æ®")

            return {
                "status": "success",
                "knowledge_data_id": saved_records[0].id if saved_records else None,
                "rows_processed": len(saved_records),
                "columns": len(rows[0]) if rows else 0
            }

        except Exception as e:
            # âœ… å‘ç”Ÿå¼‚å¸¸æ—¶å›æ»š
            self.db.rollback()
            logger.error(f"âŒ Excel å¤„ç†å¤±è´¥: {e}")
            raise

    def search_knowledge_data(
        self,
        knowledge_id: int,
        query: str,
        top_n: int = 10
    ) -> List[Dict[str, Any]]:
        """
        å…¨æ–‡æœç´¢çŸ¥è¯†æ•°æ®ï¼ˆæ¯è¡Œä¸€æ¡è®°å½•ï¼‰

        Args:
            knowledge_id: çŸ¥è¯†ID
            query: æœç´¢å…³é”®è¯
            top_n: è¿”å›ç»“æœæ•°é‡

        Returns:
            åŒ¹é…çš„è¡Œæ•°æ®
        """
        try:
            search_query = sql_text(f"""
                SELECT
                    id,
                    knowledge_id,
                    content,
                    ts_rank(fts_content, websearch_to_tsquery('zhparsercfg', :query)) AS rank_score
                FROM {global_schema}.knowledge_data
                WHERE
                    knowledge_id = :knowledge_id
                    AND fts_content @@ websearch_to_tsquery('zhparsercfg', :query)
                    AND status = 'active'
                ORDER BY rank_score DESC
                LIMIT :top_n
            """)

            result = self.db.execute(search_query, {
                "knowledge_id": knowledge_id,
                "query": query,
                "top_n": top_n
            })

            rows = result.fetchall()

            # æ¯æ¡è®°å½•æœ¬èº«å°±æ˜¯ä¸€è¡Œæ•°æ®ï¼Œç›´æ¥è¿”å›
            results = []
            for row in rows:
                results.append({
                    "row": row.content,  # content ç°åœ¨æ˜¯å•è¡Œæ•°æ®å¯¹è±¡
                    "score": float(row.rank_score),
                    "knowledge_data_id": row.id
                })

            logger.info(f"âœ… æœç´¢å®Œæˆ: æ‰¾åˆ° {len(results)} æ¡åŒ¹é…è®°å½•")
            return results

        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

    def search_knowledge_data_vector(
        self,
        knowledge_id: Optional[int],
        query: str,
        threshold: float = 0.7,
        top_n: int = 10
    ) -> List[Dict[str, Any]]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœç´¢çŸ¥è¯†æ•°æ®

        Args:
            knowledge_id: çŸ¥è¯†IDï¼ˆå¯é€‰ï¼ŒNone è¡¨ç¤ºæœç´¢æ‰€æœ‰ï¼‰
            query: æœç´¢å…³é”®è¯
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œé»˜è®¤0.7
            top_n: è¿”å›ç»“æœæ•°é‡

        Returns:
            åŒ¹é…çš„è¡Œæ•°æ®åŠç›¸ä¼¼åº¦åˆ†æ•°
        """
        try:
            # 1. è·å–æŸ¥è¯¢æ–‡æœ¬çš„å‘é‡
            query_embedding = get_text_embeddings_default(query)

            if not query_embedding:
                logger.error(f"âŒ æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–å¤±è´¥: {query}")
                return []

            # 2. å°†å‘é‡è½¬æ¢ä¸º PostgreSQL vector æ ¼å¼
            vector_str = f'[{",".join(map(str, query_embedding))}]'

            # 3. åŠ¨æ€æ„å»º SQL æ¡ä»¶
            if knowledge_id is not None:
                # æœç´¢æŒ‡å®š knowledge_id
                where_clause = "knowledge_id = :knowledge_id"
            else:
                # æœç´¢æ‰€æœ‰ knowledge_id
                where_clause = "1=1"

            # 4. æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æœç´¢
            search_query = sql_text(f"""
                SELECT
                    id,
                    knowledge_id,
                    content,
                    1 - (fts_vector <=> :query_vector) AS similarity_score
                FROM {global_schema}.knowledge_data
                WHERE
                    {where_clause}
                    AND fts_vector IS NOT NULL
                    AND 1 - (fts_vector <=> :query_vector) >= :threshold
                    AND status = 'active'
                ORDER BY similarity_score DESC
                LIMIT :top_n
            """)

            params = {
                "query_vector": vector_str,
                "threshold": threshold,
                "top_n": top_n
            }
            if knowledge_id is not None:
                params["knowledge_id"] = knowledge_id

            result = self.db.execute(search_query, params)
            rows = result.fetchall()

            # 5. æ ¼å¼åŒ–ç»“æœ
            results = []
            for row in rows:
                results.append({
                    "row": row.content,
                    "score": float(row.similarity_score),
                    "knowledge_id": row.knowledge_id,  # æ·»åŠ  knowledge_id
                    "knowledge_data_id": row.id
                })

            logger.info(f"âœ… å‘é‡æœç´¢å®Œæˆ: æ‰¾åˆ° {len(results)} æ¡åŒ¹é…è®°å½• (é˜ˆå€¼={threshold})")
            return results

        except Exception as e:
            logger.error(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            raise
